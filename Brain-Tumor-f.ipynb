{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bab8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing needed python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings as wr\n",
    "#Ignoring warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "wr.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Brain_tumor_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd431cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Target       Mean     Variance  Standard Deviation   Entropy   Skewness  \\\n",
      "0       1  23.448517  2538.985627           50.388348  0.651174   1.984202   \n",
      "1       1   4.398331   834.853030           28.893823  0.953532   6.495203   \n",
      "2       1   3.244263   642.059166           25.338886  0.966065   7.772860   \n",
      "3       0   8.511353  1126.214187           33.559115  0.868765   3.763142   \n",
      "4       0  21.000793  2235.316978           47.279139  0.684724   1.936029   \n",
      "5       0  11.350555   998.972243           31.606522  0.761106   2.533920   \n",
      "6       1   0.405136    68.378718            8.269143  0.994724  20.388025   \n",
      "7       1   5.955872   937.438650           30.617620  0.926931   5.015434   \n",
      "8       1   6.184021   895.196827           29.919840  0.917259   4.707172   \n",
      "9       1   0.260590    52.284893            7.230829  0.997061  27.722763   \n",
      "\n",
      "     Kurtosis    Contrast    Energy       ASM  Homogeneity  Dissimilarity  \\\n",
      "0    5.421042  181.467713  0.781557  0.610831     0.847033       2.765411   \n",
      "1   43.349355   76.745886  0.972770  0.946281     0.980762       0.548605   \n",
      "2   61.756034   81.752406  0.980161  0.960715     0.985066       0.540411   \n",
      "3   15.107579  362.291213  0.921786  0.849690     0.949295       2.765725   \n",
      "4    4.722343  312.439226  0.804184  0.646711     0.880301       3.006660   \n",
      "5    7.394586  303.947978  0.854277  0.729789     0.902355       3.440551   \n",
      "6  416.843433   17.789156  0.996932  0.993873     0.997885       0.114400   \n",
      "7   26.150440   57.226813  0.956961  0.915774     0.974157       0.507706   \n",
      "8   23.168174   73.714121  0.951172  0.904729     0.969454       0.686158   \n",
      "9  769.489551   18.016283  0.998292  0.996586     0.998987       0.091771   \n",
      "\n",
      "   Correlation     Coarseness        PSNR      SSIM       MSE        DC  \n",
      "0     0.968576  7.460000e-155   97.974630  0.777011  0.171163  0.303989  \n",
      "1     0.959751  7.460000e-155  110.346597  0.977953  0.009913  0.839019  \n",
      "2     0.944259  7.460000e-155  112.266298  0.985362  0.006372  0.849775  \n",
      "3     0.859027  7.460000e-155  101.955792  0.881015  0.068437  0.000000  \n",
      "4     0.938572  7.460000e-155   97.639870  0.766308  0.184878  0.000000  \n",
      "5     0.866480  7.460000e-155   99.206579  0.794881  0.128889  0.000000  \n",
      "6     0.886144  7.460000e-155  111.371193  0.985175  0.007830  0.410458  \n",
      "7     0.973263  7.460000e-155  111.439129  0.981891  0.007708  0.914484  \n",
      "8     0.963931  7.460000e-155  113.069960  0.983963  0.005295  0.945252  \n",
      "9     0.849200  7.460000e-155   67.179837  0.982749  0.012448  0.191657  \n",
      "(1275, 18)\n",
      "Target                0\n",
      "Mean                  0\n",
      "Variance              0\n",
      "Standard Deviation    0\n",
      "Entropy               0\n",
      "Skewness              0\n",
      "Kurtosis              0\n",
      "Contrast              0\n",
      "Energy                0\n",
      "ASM                   0\n",
      "Homogeneity           0\n",
      "Dissimilarity         0\n",
      "Correlation           0\n",
      "Coarseness            0\n",
      "PSNR                  0\n",
      "SSIM                  0\n",
      "MSE                   0\n",
      "DC                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))#Print all data of top 10 rows\n",
    "print(df.shape)#Print the row and clumn count of the data\n",
    "print(df.isna().sum())#Print all columns with empty data along with sum of empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc8d990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=1)#Drop the column with empty data\n",
    "#Encoding first column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "df.iloc[:,0]=labelencoder_X.fit_transform(df.iloc[:,0].values)\n",
    "#Splitting data for dependence\n",
    "X=df.iloc[:,1:].values\n",
    "Y=df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a994900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccd32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54714182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing algorithm libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299206d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for  different models\n",
    "def models(X_train,Y_train):\n",
    "\n",
    "    #Logistic regression\n",
    "    log=LogisticRegression(random_state=0)\n",
    "    log.fit(X_train,Y_train)\n",
    "\n",
    "    #Decision tree\n",
    "    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "    tree.fit(X_train,Y_train)\n",
    "\n",
    "    #Random forest classifier\n",
    "    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "    forest.fit(X_train,Y_train)\n",
    "\n",
    "    #GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,Y_train)\n",
    "\n",
    "    #Printing accuracy\n",
    "    print(\"Logistic regression:\",log.score(X_train,Y_train))\n",
    "    print(\"Decision Tree:\",tree.score(X_train,Y_train))\n",
    "    print(\"Random Forest:\",forest.score(X_train,Y_train))\n",
    "    print(\"GaussianNB:\",gnb.score(X_train,Y_train))\n",
    "    return log,tree,forest,gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c7e74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression: 0.9738493723849372\n",
      "Decision Tree: 1.0\n",
      "Random Forest: 1.0\n",
      "GaussianNB: 0.9801255230125523\n"
     ]
    }
   ],
   "source": [
    "#Testing Function for all models\n",
    "model=models(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c887a141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: 1\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.86      0.62        14\n",
      "           1       0.99      0.96      0.97       305\n",
      "\n",
      "    accuracy                           0.95       319\n",
      "   macro avg       0.74      0.91      0.80       319\n",
      "weighted avg       0.97      0.95      0.96       319\n",
      "\n",
      "Accuracy Score: 0.9529780564263323\n",
      "\n",
      "Model: 2\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.93      0.59        14\n",
      "           1       1.00      0.94      0.97       305\n",
      "\n",
      "    accuracy                           0.94       319\n",
      "   macro avg       0.71      0.94      0.78       319\n",
      "weighted avg       0.97      0.94      0.95       319\n",
      "\n",
      "Accuracy Score: 0.9435736677115988\n",
      "\n",
      "Model: 3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64        14\n",
      "           1       1.00      0.95      0.97       305\n",
      "\n",
      "    accuracy                           0.95       319\n",
      "   macro avg       0.73      0.97      0.80       319\n",
      "weighted avg       0.98      0.95      0.96       319\n",
      "\n",
      "Accuracy Score: 0.9498432601880877\n",
      "\n",
      "Model: 4\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.96      1.00      0.98       305\n",
      "\n",
      "    accuracy                           0.96       319\n",
      "   macro avg       0.48      0.50      0.49       319\n",
      "weighted avg       0.91      0.96      0.93       319\n",
      "\n",
      "Accuracy Score: 0.9561128526645768\n"
     ]
    }
   ],
   "source": [
    "#Metrics of the models\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(model)):\n",
    "    print(\"\\nModel:\",i+1)\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(Y_test,model[i].predict(X_test)))\n",
    "    print(\"Accuracy Score:\",accuracy_score(Y_test,model[i].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3e94f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "[[ 12   2]\n",
      " [ 13 292]]\n",
      "Testing Accuracy =  0.9529780564263323\n",
      "\n",
      "Model 1\n",
      "[[ 13   1]\n",
      " [ 17 288]]\n",
      "Testing Accuracy =  0.9435736677115988\n",
      "\n",
      "Model 2\n",
      "[[ 14   0]\n",
      " [ 16 289]]\n",
      "Testing Accuracy =  0.9498432601880877\n",
      "\n",
      "Model 3\n",
      "[[  0  14]\n",
      " [  0 305]]\n",
      "Testing Accuracy =  0.9561128526645768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range( len(model)):\n",
    "  print('Model', i)\n",
    "  cm = confusion_matrix(Y_test, model[i].predict(X_test))\n",
    "\n",
    "  TP = cm[0][0]\n",
    "  TN = cm[1][1]\n",
    "  FN = cm[1][0]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(cm)\n",
    "  print('Testing Accuracy = ',(TP + TN)/(TP + TN + FN + FP))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c63a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2436cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings as wr\n",
    "#Ignoring warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "wr.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5acd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Colorectal_cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a1450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id diagnosis_result  radius  texture  perimeter  area  smoothness  \\\n",
      "0   1                M      23       12        151   954       0.143   \n",
      "1   2                B       9       13        133  1326       0.143   \n",
      "2   3                M      21       27        130  1203       0.125   \n",
      "3   4                M      14       16         78   386       0.070   \n",
      "4   5                M       9       19        135  1297       0.141   \n",
      "5   6                B      25       25         83   477       0.128   \n",
      "6   7                M      16       26        120  1040       0.095   \n",
      "7   8                M      15       18         90   578       0.119   \n",
      "8   9                M      19       24         88   520       0.127   \n",
      "9  10                M      25       11         84   476       0.119   \n",
      "\n",
      "   compactness  symmetry  fractal_dimension  \n",
      "0        0.278     0.242              0.079  \n",
      "1        0.079     0.181              0.057  \n",
      "2        0.160     0.207              0.060  \n",
      "3        0.284     0.260              0.097  \n",
      "4        0.133     0.181              0.059  \n",
      "5        0.170     0.209              0.076  \n",
      "6        0.109     0.179              0.057  \n",
      "7        0.165     0.220              0.075  \n",
      "8        0.193     0.235              0.074  \n",
      "9        0.240     0.203              0.082  \n",
      "(100, 10)\n",
      "id                   0\n",
      "diagnosis_result     0\n",
      "radius               0\n",
      "texture              0\n",
      "perimeter            0\n",
      "area                 0\n",
      "smoothness           0\n",
      "compactness          0\n",
      "symmetry             0\n",
      "fractal_dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))#Print all data of top 10 rows\n",
    "print(df.shape)#Print the row and clumn count of the data\n",
    "print(df.isna().sum())#Print all columns with empty data along with sum of empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6dc686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=1)#Drop the column with empty data\n",
    "df=df.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31be82c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X=LabelEncoder()#Calling LabelEncoder\n",
    "df.iloc[:,0]=labelencoder_X.fit_transform(df.iloc[:,0].values)#Encoding the values of diagnosis column to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e419f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:].values#Features of cancerous and non cancerous patients\n",
    "Y=df.iloc[:,0].values#Whether patient has cancer or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de1d38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60da4348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)#Scaling X_train\n",
    "X_test=sc.fit_transform(X_test)#Scaling X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904cc0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99e6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for  different models\n",
    "def models(X_train,Y_train):\n",
    "\n",
    "    #Logistic regression\n",
    "    log=LogisticRegression(random_state=0)\n",
    "    log.fit(X_train,Y_train)\n",
    "\n",
    "    #Decision tree\n",
    "    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "    tree.fit(X_train,Y_train)\n",
    "\n",
    "    #Random forest classifier\n",
    "    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "    forest.fit(X_train,Y_train)\n",
    "\n",
    "    #GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,Y_train)\n",
    "\n",
    "    #Printing accuracy\n",
    "    print(\"Logistic regression:\",log.score(X_train,Y_train))\n",
    "    print(\"Decision Tree:\",tree.score(X_train,Y_train))\n",
    "    print(\"Random Forest:\",forest.score(X_train,Y_train))\n",
    "    print(\"GaussianNB:\",gnb.score(X_train,Y_train))\n",
    "    return log,tree,forest,gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9641f2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Logistic regression: 0.9\n",
      "Decision Tree: 1.0\n",
      "Random Forest: 1.0\n",
      "GaussianNB: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\")\n",
    "model=models(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ede986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: 1\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.86      0.80      0.79        10\n",
      "weighted avg       0.86      0.80      0.79        10\n",
      "\n",
      "Accuracy Score: 0.8\n",
      "\n",
      "Model: 2\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.20      0.25         5\n",
      "           1       0.43      0.60      0.50         5\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.38      0.40      0.38        10\n",
      "weighted avg       0.38      0.40      0.38        10\n",
      "\n",
      "Accuracy Score: 0.4\n",
      "\n",
      "Model: 3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75         5\n",
      "           1       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.86      0.80      0.79        10\n",
      "weighted avg       0.86      0.80      0.79        10\n",
      "\n",
      "Accuracy Score: 0.8\n",
      "\n",
      "Model: 4\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67         5\n",
      "           1       0.67      0.80      0.73         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.71      0.70      0.70        10\n",
      "weighted avg       0.71      0.70      0.70        10\n",
      "\n",
      "Accuracy Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(model)):\n",
    "    print(\"\\nModel:\",i+1)\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(Y_test,model[i].predict(X_test)))\n",
    "    print(\"Accuracy Score:\",accuracy_score(Y_test,model[i].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350c6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41370db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "948f3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(X_train,Y_train):\n",
    "\n",
    "    #Logistic regression\n",
    "    log=LogisticRegression(random_state=0)\n",
    "    log.fit(X_train,Y_train)\n",
    "\n",
    "    #Decision tree\n",
    "    tree=DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "    tree.fit(X_train,Y_train)\n",
    "\n",
    "    #Random forest classifier\n",
    "    forest=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\n",
    "    forest.fit(X_train,Y_train)\n",
    "\n",
    "    #GaussianNB\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train,Y_train)\n",
    "\n",
    "    #Printing accuracy\n",
    "    print(\"Logistic regression:\",log.score(X_train,Y_train))\n",
    "    print(\"Decision Tree:\",tree.score(X_train,Y_train))\n",
    "    print(\"Random Forest:\",forest.score(X_train,Y_train))\n",
    "    print(\"GaussianNB:\",gnb.score(X_train,Y_train))\n",
    "    return log,tree,forest,gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ba970a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Logistic regression: 0.8285714285714286\n",
      "Decision Tree: 1.0\n",
      "Random Forest: 0.9857142857142858\n",
      "GaussianNB: 0.7428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\")\n",
    "model=models(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c19e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: 1\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82         9\n",
      "           1       0.91      0.95      0.93        21\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.89      0.87      0.88        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "Accuracy Score: 0.9\n",
      "\n",
      "Model: 2\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.78      0.54         9\n",
      "           1       0.85      0.52      0.65        21\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.63      0.65      0.59        30\n",
      "weighted avg       0.72      0.60      0.61        30\n",
      "\n",
      "Accuracy Score: 0.6\n",
      "\n",
      "Model: 3\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70         9\n",
      "           1       0.89      0.81      0.85        21\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.77      0.79      0.78        30\n",
      "weighted avg       0.82      0.80      0.81        30\n",
      "\n",
      "Accuracy Score: 0.8\n",
      "\n",
      "Model: 4\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73         9\n",
      "           1       0.94      0.76      0.84        21\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.78      0.83      0.78        30\n",
      "weighted avg       0.84      0.80      0.81        30\n",
      "\n",
      "Accuracy Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(model)):\n",
    "    print(\"\\nModel:\",i+1)\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(Y_test,model[i].predict(X_test)))\n",
    "    print(\"Accuracy Score:\",accuracy_score(Y_test,model[i].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d22c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "[[ 7  2]\n",
      " [ 1 20]]\n",
      "Testing Accuracy =  0.9\n",
      "\n",
      "Model 1\n",
      "[[ 7  2]\n",
      " [10 11]]\n",
      "Testing Accuracy =  0.6\n",
      "\n",
      "Model 2\n",
      "[[ 7  2]\n",
      " [ 4 17]]\n",
      "Testing Accuracy =  0.8\n",
      "\n",
      "Model 3\n",
      "[[ 8  1]\n",
      " [ 5 16]]\n",
      "Testing Accuracy =  0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range( len(model)):\n",
    "  print('Model', i)\n",
    "  cm = confusion_matrix(Y_test, model[i].predict(X_test))\n",
    "\n",
    "  TP = cm[0][0]\n",
    "  TN = cm[1][1]\n",
    "  FN = cm[1][0]\n",
    "  FP = cm[0][1]\n",
    "\n",
    "  print(cm)\n",
    "  print('Testing Accuracy = ',(TP + TN)/(TP + TN + FN + FP))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
